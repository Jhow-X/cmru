import express from 'express';
import multer from 'multer';
import dotenv from 'dotenv';
import { OpenAI } from 'openai';
import fs from 'fs/promises';
import path from 'path';

dotenv.config();

const app = express();
const port = 3000;
const upload = multer({ dest: 'uploads/' });
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// Store vector store ID globally (or use a database for persistence)
let vectorStoreId: string | null = null;

// Upload and store files in vector storage
app.post('/upload', upload.array('files'), async (req, res) => {
  try {
    const files = req.files as Express.Multer.File[];

    if (!files.length) {
      return res.status(400).json({ error: 'No files uploaded' });
    }

    // Upload files to OpenAI
    const uploadedFiles = await Promise.all(
      files.map(file =>
        openai.files.create({
          file: fs.createReadStream(file.path),
          purpose: 'assistants',
        })
      )
    );

    // Create vector store with uploaded files
    const vectorStore = await openai.beta.vectorStores.create({
      name: 'context-store',
      file_ids: uploadedFiles.map(f => f.id),
    });

    vectorStoreId = vectorStore.id;

    // Cleanup local files
    for (const file of files) {
      await fs.unlink(file.path);
    }

    res.json({ message: 'Files uploaded and stored', vectorStoreId });
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to upload and store files' });
  }
});

// Use the stored context in a chat completion
app.post('/chat', express.json(), async (req, res) => {
  try {
    const { message } = req.body;

    if (!message || !vectorStoreId) {
      return res.status(400).json({ error: 'Missing message or vector store not initialized' });
    }

    const assistant = await openai.beta.assistants.create({
      name: 'Context Assistant',
      model: 'gpt-4o',
      tools: [{ type: 'retrieval' }],
      tool_resources: {
        vector_stores: [vectorStoreId],
      },
    });

    const thread = await openai.beta.threads.create();

    await openai.beta.threads.messages.create(thread.id, {
      role: 'user',
      content: message,
    });

    const run = await openai.beta.threads.runs.create(thread.id, {
      assistant_id: assistant.id,
    });

    // Poll until the run is completed
    let runStatus = run.status;
    while (runStatus !== 'completed' && runStatus !== 'failed') {
      const updatedRun = await openai.beta.threads.runs.retrieve(thread.id, run.id);
      runStatus = updatedRun.status;
      await new Promise(res => setTimeout(res, 1000));
    }

    if (runStatus === 'failed') {
      return res.status(500).json({ error: 'Run failed' });
    }

    const messages = await openai.beta.threads.messages.list(thread.id);

    const lastMessage = messages.data.find(m => m.role === 'assistant');

    res.json({ response: lastMessage?.content[0].text.value });
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Chat failed' });
  }
});

app.listen(port, () => {
  console.log(`Server is running on http://localhost:${port}`);
});
